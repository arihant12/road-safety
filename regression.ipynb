{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5793796,"sourceType":"datasetVersion","datasetId":199387}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-14T07:03:15.916220Z","iopub.execute_input":"2024-11-14T07:03:15.916943Z","iopub.status.idle":"2024-11-14T07:03:17.069558Z","shell.execute_reply.started":"2024-11-14T07:03:15.916886Z","shell.execute_reply":"2024-11-14T07:03:17.068324Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/us-accidents/US_Accidents_March23.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import LabelEncoder\n\n# Step 1: Load the dataset\ndf = pd.read_csv('/kaggle/input/us-accidents/US_Accidents_March23.csv')  # Update with your file path\nprint(\"Dataset loaded successfully. Columns are:\\n\", df.columns)\n\n# Step 2: Convert `Severity` to binary classification\n# Convert Severity to binary classification: 1 for Severe (3 and 4), 0 for Non-Severe (1 and 2)\ndf['Severity'] = df['Severity'].apply(lambda x: 1 if x >= 3 else 0)\nprint(\"Unique values in Severity column after conversion:\", df['Severity'].unique())\n\n# Step 3: Select relevant columns for the prediction task\n# Adjust column names based on the actual names in your dataset\ndf = df[['Severity', 'Weather_Condition', 'Sunrise_Sunset', 'Civil_Twilight', 'Traffic_Signal']]\nprint(\"Selected columns:\\n\", df.head())\n\n# Step 4: Drop rows with missing values\ndf = df.dropna()\nprint(\"Data after dropping missing values. Shape:\", df.shape)\n\n# Step 5: Verify class distribution after conversion\n# Ensure both classes are present before proceeding with balancing\nprint(\"Class distribution in Severity after conversion:\\n\", df['Severity'].value_counts())\n\n# Step 6: Balance the dataset with partial oversampling\n# Separate majority and minority classes\ndf_majority = df[df['Severity'] == 0]  # Non-Severe\ndf_minority = df[df['Severity'] == 1]  # Severe\n\n# Set the target minority size to 70% of the majority class size (adjust percentage as needed)\ntarget_minority_size = int(0.55 * len(df_majority))\n\n# Perform partial oversampling on the minority class\ndf_minority_oversampled = resample(df_minority, \n                                   replace=True,                 # Sample with replacement\n                                   n_samples=target_minority_size,  # 70% of majority class size\n                                   random_state=42)              # For reproducibility\n\n# Combine majority class with partially oversampled minority class\ndf_balanced = pd.concat([df_majority, df_minority_oversampled])\n\n# Shuffle the balanced dataset\ndf_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Display new class distribution\nprint(\"Balanced class distribution:\\n\", df_balanced['Severity'].value_counts())\n\n# Step 7: Encode categorical columns to numeric values\n# Define features and target from the balanced dataset\nX = df_balanced.drop(columns=['Severity'])\ny = df_balanced['Severity']\n\n# Encode categorical columns\nlabel_encoder = LabelEncoder()\nfor column in X.columns:\n    if X[column].dtype == 'object':  # Check if the column is of type object (i.e., categorical)\n        X[column] = label_encoder.fit_transform(X[column])\n\nprint(\"Encoding completed. Sample data:\\n\", X.head())\n\n# Step 8: Split the data into training and testing sets with stratified sampling\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n# Display the class distribution in the training and testing sets\nprint(\"Training set class distribution:\\n\", y_train.value_counts())\nprint(\"Testing set class distribution:\\n\", y_test.value_counts())\n\n# Step 9: Train Logistic Regression and Multinomial Naive Bayes\n\n# Logistic Regression\nlog_reg = LogisticRegression(max_iter=1000, random_state=42)\nlog_reg.fit(X_train, y_train)\n\n# Make predictions and evaluate Logistic Regression model\ny_pred_log_reg = log_reg.predict(X_test)\nprint(\"\\nLogistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\nprint(\"Logistic Regression Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log_reg))\nprint(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_log_reg))\n\n# Multinomial Naive Bayes\nmnb = MultinomialNB()\nmnb.fit(X_train, y_train)\n\n# Make predictions and evaluate Multinomial Naive Bayes model\ny_pred_mnb = mnb.predict(X_test)\nprint(\"\\nMultinomial Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_mnb))\nprint(\"Multinomial Naive Bayes Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_mnb))\nprint(\"Multinomial Naive Bayes Classification Report:\\n\", classification_report(y_test, y_pred_mnb))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T07:26:54.519768Z","iopub.execute_input":"2024-11-14T07:26:54.520214Z","iopub.status.idle":"2024-11-14T07:29:18.808481Z","shell.execute_reply.started":"2024-11-14T07:26:54.520175Z","shell.execute_reply":"2024-11-14T07:29:18.807232Z"}},"outputs":[{"name":"stdout","text":"Dataset loaded successfully. Columns are:\n Index(['ID', 'Source', 'Severity', 'Start_Time', 'End_Time', 'Start_Lat',\n       'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)', 'Description',\n       'Street', 'City', 'County', 'State', 'Zipcode', 'Country', 'Timezone',\n       'Airport_Code', 'Weather_Timestamp', 'Temperature(F)', 'Wind_Chill(F)',\n       'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Direction',\n       'Wind_Speed(mph)', 'Precipitation(in)', 'Weather_Condition', 'Amenity',\n       'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway',\n       'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal',\n       'Turning_Loop', 'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n       'Astronomical_Twilight'],\n      dtype='object')\nUnique values in Severity column after conversion: [1 0]\nSelected columns:\n    Severity Weather_Condition Sunrise_Sunset Civil_Twilight  Traffic_Signal\n0         1        Light Rain          Night          Night           False\n1         0        Light Rain          Night          Night           False\n2         0          Overcast          Night          Night            True\n3         1     Mostly Cloudy          Night            Day           False\n4         0     Mostly Cloudy            Day            Day            True\nData after dropping missing values. Shape: (7534613, 5)\nClass distribution in Severity after conversion:\n Severity\n0    6070980\n1    1463633\nName: count, dtype: int64\nBalanced class distribution:\n Severity\n0    6070980\n1    3339039\nName: count, dtype: int64\nEncoding completed. Sample data:\n    Weather_Condition  Sunrise_Sunset  Civil_Twilight  Traffic_Signal\n0                  7               0               0           False\n1                 16               0               0           False\n2                 85               0               0           False\n3                 91               0               0           False\n4                 62               0               0            True\nTraining set class distribution:\n Severity\n0    4249686\n1    2337327\nName: count, dtype: int64\nTesting set class distribution:\n Severity\n0    1821294\n1    1001712\nName: count, dtype: int64\n\nLogistic Regression Accuracy: 0.6438806718795497\nLogistic Regression Confusion Matrix:\n [[1813878    7416]\n [ 997911    3801]]\nLogistic Regression Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.65      1.00      0.78   1821294\n           1       0.34      0.00      0.01   1001712\n\n    accuracy                           0.64   2823006\n   macro avg       0.49      0.50      0.40   2823006\nweighted avg       0.54      0.64      0.51   2823006\n\n\nMultinomial Naive Bayes Accuracy: 0.6431311162640108\nMultinomial Naive Bayes Confusion Matrix:\n [[1809378   11916]\n [ 995527    6185]]\nMultinomial Naive Bayes Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.65      0.99      0.78   1821294\n           1       0.34      0.01      0.01   1001712\n\n    accuracy                           0.64   2823006\n   macro avg       0.49      0.50      0.40   2823006\nweighted avg       0.54      0.64      0.51   2823006\n\n","output_type":"stream"}],"execution_count":7}]}